import pandas as pd
import json
import os
import sys
from pathlib import Path
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from statsmodels.tsa.arima.model import ARIMA
from utils import LoggerSetup, retry_on_failure, get_taiwan_time, config_manager, slack_alert, get_clean_symbol
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from openai import OpenAI
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

logger = LoggerSetup.setup_logger('strategy_manager', config_manager.get("system.log_level", "INFO") if config_manager else "INFO")

def get_grok_client():
    """ç²å– Grok API å®¢æˆ¶ç«¯"""
    if not config_manager:
        raise ValueError("é…ç½®ç®¡ç†å™¨æœªåˆå§‹åŒ–")

    api_key = config_manager.get_secret('api_keys.grok_api_key') or os.getenv('GROK_API_KEY')
    if not api_key:
        raise ValueError("æœªé…ç½® GROK_API_KEY")

    base_url = config_manager.get('llm.grok_api_url', "https://api.x.ai/v1")

    return OpenAI(
        api_key=api_key,
        base_url=base_url
    )

@retry_on_failure(max_retries=3, delay=3.0)
def optimize_params(strategy_name, params, performance):
    """ä½¿ç”¨ Grok API å„ªåŒ–ç­–ç•¥åƒæ•¸"""
    try:
        client = get_grok_client()

        prompt = f"""
        è«‹ç‚º {strategy_name} ç­–ç•¥å„ªåŒ–åƒæ•¸ï¼Œç”¨æ–¼çŸ­æœŸè‚¡ç¥¨äº¤æ˜“ï¼ˆ1-3å¤©ï¼‰ã€‚
        
        ç•¶å‰è¡¨ç¾: {performance}
        ç•¶å‰åƒæ•¸: {json.dumps(params, indent=2)}
        
        è«‹åŸºæ–¼ä»¥ä¸‹åŸå‰‡å„ªåŒ–åƒæ•¸:
        1. æŠ€è¡“åˆ†æç­–ç•¥: èª¿æ•´ç§»å‹•å¹³å‡ç·šé€±æœŸã€RSIåƒæ•¸ç­‰
        2. æ©Ÿå™¨å­¸ç¿’ç­–ç•¥: èª¿æ•´æ¨¡å‹è¶…åƒæ•¸
        3. æ·±åº¦å­¸ç¿’ç­–ç•¥: èª¿æ•´ç¶²è·¯çµæ§‹åƒæ•¸
        4. æƒ…ç·’åˆ†æç­–ç•¥: èª¿æ•´æƒ…ç·’é–¾å€¼
        
        è«‹è¿”å›å„ªåŒ–å¾Œçš„åƒæ•¸ï¼Œæ ¼å¼ç‚ºç´”JSONï¼ˆä¸è¦åŒ…å«ä»»ä½•è§£é‡‹æ–‡å­—ï¼‰ï¼š
        {{
            "param1": value1,
            "param2": value2
        }}
        """
        
        response = client.chat.completions.create(
            model=config_manager.get('llm.grok_model', "grok-beta") if config_manager else "grok-beta",
            messages=[{"role": "user", "content": prompt}],
            temperature=config_manager.get('llm.temperature', 0.3) if config_manager else 0.3,
            max_tokens=config_manager.get('llm.max_tokens', 1000) if config_manager else 1000
        )
        
        response_text = response.choices[0].message.content.strip()
        
        # å˜—è©¦è§£æJSON
        import re
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            try:
                optimized_params = json.loads(json_match.group())
                logger.info(f"æˆåŠŸå„ªåŒ– {strategy_name} ç­–ç•¥åƒæ•¸")
                return optimized_params
            except json.JSONDecodeError as e:
                logger.warning(f"è§£æå„ªåŒ–åƒæ•¸JSONå¤±æ•—: {e}")
        
        logger.warning(f"ç„¡æ³•è§£æ Grok API å›æ‡‰ï¼Œä½¿ç”¨åŸå§‹åƒæ•¸")
        return params
            
    except Exception as e:
        logger.error(f"å„ªåŒ–ç­–ç•¥åƒæ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return params

def load_strategies_config():
    """è¼‰å…¥ç­–ç•¥é…ç½®"""
    try:
        if not config_manager:
            logger.error("é…ç½®ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨é è¨­ç­–ç•¥")
            return get_default_strategies()

        strategies_config = config_manager.strategies_config
        if not strategies_config or 'available_strategies' not in strategies_config:
            logger.error("ç­–ç•¥é…ç½®æª”æ¡ˆæ ¼å¼éŒ¯èª¤æˆ–ç‚ºç©ºï¼Œä½¿ç”¨é è¨­ç­–ç•¥")
            return get_default_strategies()
        
        strategies = []
        for strategy_key, strategy_info in strategies_config['available_strategies'].items():
            if strategy_info.get('enabled', False):
                strategy = {
                    'name': strategy_key,
                    'display_name': strategy_info.get('name', strategy_key),
                    'params': strategy_info.get('parameters', {}),
                    'weight': strategy_info.get('weight', 0.25)
                }
                strategies.append(strategy)
        
        logger.info(f"è¼‰å…¥ {len(strategies)} å€‹å•Ÿç”¨çš„ç­–ç•¥")
        return strategies if strategies else get_default_strategies()
        
    except Exception as e:
        logger.error(f"è¼‰å…¥ç­–ç•¥é…ç½®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return get_default_strategies()

def get_default_strategies():
    """ç²å–é è¨­ç­–ç•¥é…ç½®"""
    return [
        {
            'name': 'technical_analysis',
            'display_name': 'æŠ€è¡“åˆ†æç­–ç•¥',
            'params': {
                'sma_short': 20,
                'sma_long': 50,
                'rsi_period': 14,
                'rsi_overbought': 70,
                'rsi_oversold': 30
            },
            'weight': 0.4
        },
        {
            'name': 'ml_random_forest',
            'display_name': 'éš¨æ©Ÿæ£®æ—ç­–ç•¥',
            'params': {
                'n_estimators': 100,
                'max_depth': 10,
                'min_samples_split': 5
            },
            'weight': 0.3
        },
        {
            'name': 'sentiment_analysis',
            'display_name': 'æƒ…ç·’åˆ†æç­–ç•¥',
            'params': {
                'sentiment_threshold': 0.1
            },
            'weight': 0.3
        }
    ]

def load_market_data(symbol: str, data_type: str = "daily") -> pd.DataFrame:
    """è¼‰å…¥å¸‚å ´æ•¸æ“š"""
    try:
        clean_symbol = get_clean_symbol(symbol)

        # å˜—è©¦å¤šå€‹å¯èƒ½çš„æª”æ¡ˆä½ç½®
        possible_paths = []
        
        if config_manager:
            # ä½¿ç”¨é…ç½®ç®¡ç†å™¨ç²å–æ•¸æ“šè·¯å¾‘
            data_path = config_manager.get_data_path("market")
            possible_paths.append(data_path / f"{data_type}_{clean_symbol}.csv")
        
        # å‚™ç”¨è·¯å¾‘
        possible_paths.extend([
            Path("data/market") / f"{data_type}_{clean_symbol}.csv",
            Path.cwd() / "data" / "market" / f"{data_type}_{clean_symbol}.csv",
            Path(__file__).parent.parent / "data" / "market" / f"{data_type}_{clean_symbol}.csv"
        ])
        
        for file_path in possible_paths:
            if file_path.exists():
                logger.info(f"è¼‰å…¥æ•¸æ“šæª”æ¡ˆ: {file_path}")
                df = pd.read_csv(file_path, parse_dates=['Datetime'])
                logger.info(f"æˆåŠŸè¼‰å…¥ {symbol} æ•¸æ“šï¼Œå…± {len(df)} ç­†è¨˜éŒ„")
                return df
        
        logger.error(f"æ‰¾ä¸åˆ° {symbol} çš„æ•¸æ“šæª”æ¡ˆï¼Œå˜—è©¦çš„è·¯å¾‘: {[str(p) for p in possible_paths]}")
        return None
        
    except Exception as e:
        logger.error(f"è¼‰å…¥ {symbol} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

def load_news_sentiment(symbol: str, date: str) -> float:
    """å¾æ–°èæ•¸æ“šè¨ˆç®—æƒ…ç·’åˆ†æ•¸"""
    try:
        # å˜—è©¦å¤šå€‹å¯èƒ½çš„æ–°èç›®éŒ„
        possible_dirs = []
        
        if config_manager:
            news_path = config_manager.get_data_path("news") / date
            possible_dirs.append(news_path)
        
        # å‚™ç”¨è·¯å¾‘
        possible_dirs.extend([
            Path("data/news") / date,
            Path.cwd() / "data" / "news" / date,
            Path(__file__).parent.parent / "data" / "news" / date
        ])
        
        news_dir = None
        for dir_path in possible_dirs:
            if dir_path.exists():
                news_dir = dir_path
                break
        
        if not news_dir:
            logger.debug(f"æ–°èç›®éŒ„ {date} ä¸å­˜åœ¨ï¼Œè¿”å›ä¸­æ€§æƒ…ç·’åˆ†æ•¸")
            return 0.0
        
        sentiment_scores = []
        
        # è®€å–ç›¸é—œæ–°èæª”æ¡ˆ
        market_type = "taiwan" if "TW" in symbol else "us"
        pattern = f"news_{market_type}_*.json"
        
        for news_file in news_dir.glob(pattern):
            try:
                with open(news_file, 'r', encoding='utf-8') as f:
                    news = json.load(f)
                
                # ç°¡åŒ–çš„æƒ…ç·’åˆ†æï¼ˆå¯¦éš›ç’°å¢ƒä¸­æ‡‰ä½¿ç”¨ Grok APIï¼‰
                summary = news.get('summary', '') or news.get('title', '')
                if not summary:
                    continue
                
                # æ¨¡æ“¬æƒ…ç·’åˆ†æ - åŸºæ–¼é—œéµå­—
                positive_keywords = ['ä¸Šæ¼²', 'çªç ´', 'å‰µæ–°é«˜', 'åˆ©å¥½', 'å¼·å‹¢', 'çœ‹å¥½', 'è²·å…¥']
                negative_keywords = ['ä¸‹è·Œ', 'è·Œç ´', 'å‰µæ–°ä½', 'åˆ©ç©º', 'å¼±å‹¢', 'çœ‹æ·¡', 'è³£å‡º']
                
                positive_count = sum(1 for keyword in positive_keywords if keyword in summary)
                negative_count = sum(1 for keyword in negative_keywords if keyword in summary)
                
                if positive_count > negative_count:
                    score = 0.3 + (positive_count - negative_count) * 0.1
                elif negative_count > positive_count:
                    score = -0.3 - (negative_count - positive_count) * 0.1
                else:
                    score = 0.0
                
                # é™åˆ¶åˆ†æ•¸ç¯„åœåœ¨ -1 åˆ° 1 ä¹‹é–“
                score = max(-1.0, min(1.0, score))
                sentiment_scores.append(score)
                
            except Exception as e:
                logger.warning(f"è™•ç†æ–°è {news_file} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        avg_sentiment = np.mean(sentiment_scores) if sentiment_scores else 0.0
        logger.debug(f"{symbol} æƒ…ç·’åˆ†æ•¸: {avg_sentiment:.3f} (åŸºæ–¼ {len(sentiment_scores)} å‰‡æ–°è)")
        return avg_sentiment

    except Exception as e:
        logger.error(f"è¨ˆç®— {symbol} æƒ…ç·’åˆ†æ•¸å¤±æ•—: {e}")
        return 0.0

def validate_data_quality(df, symbol: str, min_rows: int = 100) -> bool:
    """é©—è­‰æ•¸æ“šå“è³ª"""
    if df is None or len(df) < min_rows:
        logger.warning(f"{symbol} æ•¸æ“šè¡Œæ•¸ä¸è¶³: {len(df) if df is not None else 0}")
        return False

    required_columns = ['Datetime', 'Open', 'High', 'Low', 'Close', 'Volume']
    missing_columns = [col for col in required_columns if col not in df.columns]

    if missing_columns:
        logger.warning(f"{symbol} ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_columns}")
        return False

    null_percentage = df.isnull().sum().sum() / (len(df) * len(df.columns))
    if null_percentage > 0.1:
        logger.warning(f"{symbol} ç©ºå€¼æ¯”ä¾‹éé«˜: {null_percentage:.2%}")
        return False

    if (df['Close'] <= 0).any():
        logger.warning(f"{symbol} å­˜åœ¨ç•°å¸¸åƒ¹æ ¼æ•¸æ“š")
        return False

    logger.info(f"{symbol} æ•¸æ“šå“è³ªé©—è­‰é€šéï¼Œå…± {len(df)} ç­†è¨˜éŒ„")
    return True

def calculate_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™"""
    try:
        # ç¢ºä¿æ•¸æ“šå·²æ’åº
        df = df.sort_values('Datetime').copy()

        # åŸºæœ¬æŒ‡æ¨™
        df['Return'] = df['Close'].pct_change()
        df['Label'] = np.where(df['Return'] > 0, 1, 0)
        
        # ç§»å‹•å¹³å‡ç·š
        df['SMA_5'] = df['Close'].rolling(window=5, min_periods=1).mean()
        df['SMA_10'] = df['Close'].rolling(window=10, min_periods=1).mean()
        df['SMA_20'] = df['Close'].rolling(window=20, min_periods=1).mean()
        df['SMA_50'] = df['Close'].rolling(window=50, min_periods=1).mean()
        
        # RSI
        df['RSI'] = calculate_rsi(df['Close'], window=14)
        
        # æˆäº¤é‡æŒ‡æ¨™
        df['Volume_MA'] = df['Volume'].rolling(window=20, min_periods=1).mean()
        df['Volume_Ratio'] = df['Volume'] / df['Volume_MA']
        
        # MACD
        exp1 = df['Close'].ewm(span=12).mean()
        exp2 = df['Close'].ewm(span=26).mean()
        df['MACD'] = exp1 - exp2
        df['MACD_Signal'] = df['MACD'].ewm(span=9).mean()
        df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']
        
        # å¸ƒæ—å¸¶
        rolling_mean = df['Close'].rolling(window=20).mean()
        rolling_std = df['Close'].rolling(window=20).std()
        df['BB_Upper'] = rolling_mean + (rolling_std * 2)
        df['BB_Lower'] = rolling_mean - (rolling_std * 2)
        df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])
        
        # åƒ¹æ ¼è®Šå‹•å¹…åº¦
        df['Price_Range'] = (df['High'] - df['Low']) / df['Close']
        
        logger.debug("æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å®Œæˆ")
        return df
        
    except Exception as e:
        logger.error(f"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return df

def main(mode=None):
    """ä¸»è¦åŸ·è¡Œå‡½æ•¸"""
    try:
        logger.info(f"ç­–ç•¥ç®¡ç†å™¨é–‹å§‹åŸ·è¡Œï¼Œæ¨¡å¼: {mode or 'default'}")

        strategies = load_strategies_config()
        if not strategies:
            slack_alert("ç„¡å¯ç”¨çš„ç­–ç•¥é…ç½®", urgent=True)
            return
        
        # ç¢ºå®šç›®æ¨™è‚¡ç¥¨
        if mode == 'us':
            focus_symbol = 'QQQ'
            market_name = "ç¾è‚¡"
        else:
            focus_symbol = '0050.TW'
            market_name = "å°è‚¡"
        
        logger.info(f"åˆ†æç›®æ¨™: {focus_symbol} ({market_name})")
        
        # è¼‰å…¥æ•¸æ“š
        df = load_market_data(focus_symbol, "daily")
        if not validate_data_quality(df, focus_symbol):
            slack_alert(f"{focus_symbol} æ•¸æ“šå“è³ªä¸åˆæ ¼", urgent=True)
            return
        
        # è¨­ç½®ç´¢å¼•ä¸¦è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
        df.set_index('Datetime', inplace=True)
        df = calculate_technical_indicators(df)
        
        # æ·»åŠ æƒ…ç·’åˆ†æ•¸
        today = get_taiwan_time().strftime("%Y-%m-%d")
        sentiment_score = load_news_sentiment(focus_symbol, today)
        df['Sentiment'] = sentiment_score
        
        # æ¸…ç†æ•¸æ“š
        df.dropna(inplace=True)
        
        if len(df) < 50:
            logger.warning(f"è™•ç†å¾Œæ•¸æ“šé‡ä¸è¶³: {len(df)}")
            slack_alert(f"{focus_symbol} è™•ç†å¾Œæ•¸æ“šé‡ä¸è¶³", urgent=True)
            return
        
        logger.info(f"{focus_symbol} æ•¸æ“šé è™•ç†å®Œæˆï¼Œå…± {len(df)} ç­†è¨˜éŒ„")
        
        # è¨ˆç®—åŸºæº–æ¨¡å‹ (ARIMA)
        try:
            logger.info("è¨ˆç®— ARIMA åŸºæº–æ¨¡å‹...")
            arima_model = ARIMA(df['Close'].tail(100), order=(1,1,1)).fit()
            test_size = min(len(df) // 5, 20)
            arima_forecast = arima_model.forecast(steps=1)[0]
            current_price = df['Close'].iloc[-1]
            baseline_prediction = 1 if arima_forecast > current_price else 0
            
            # è¨ˆç®—æ­·å²æº–ç¢ºç‡
            historical_predictions = []
            actual_labels = []
            for i in range(-test_size, 0):
                try:
                    temp_model = ARIMA(df['Close'].iloc[:i-1], order=(1,1,1)).fit()
                    forecast = temp_model.forecast(steps=1)[0]
                    pred = 1 if forecast > df['Close'].iloc[i-1] else 0
                    actual = df['Label'].iloc[i]
                    historical_predictions.append(pred)
                    actual_labels.append(actual)
                except:
                    continue
            
            if historical_predictions:
                baseline_acc = accuracy_score(actual_labels, historical_predictions)
            else:
                baseline_acc = 0.5
                
            logger.info(f"ARIMA åŸºæº–æº–ç¢ºç‡: {baseline_acc:.3f}")
            
        except Exception as e:
            logger.warning(f"ARIMA åŸºæº–æ¨¡å‹å¤±æ•—: {e}, ä½¿ç”¨éš¨æ©ŸåŸºæº– 0.5")
            baseline_acc = 0.5
        
        # æº–å‚™ç‰¹å¾µ
        feature_columns = ['SMA_5', 'SMA_20', 'RSI', 'Volume_Ratio', 'MACD', 'BB_Position', 'Sentiment']
        available_features = [col for col in feature_columns if col in df.columns]
        
        if not available_features:
            logger.error("æ²’æœ‰å¯ç”¨çš„ç‰¹å¾µæ¬„ä½")
            return
        
        X = df[available_features].fillna(0)
        y = df['Label']
        
        # æ™‚é–“åºåˆ—åˆ†å‰²
        tscv = TimeSeriesSplit(n_splits=3)
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, shuffle=False
        )
        
        strategy_results = {}
        best_win_rate = 0
        best_strategy = None
        best_params = None
        
        logger.info(f"é–‹å§‹è©•ä¼° {len(strategies)} å€‹ç­–ç•¥...")
        
        for strategy in strategies:
            name = strategy['name']
            params = strategy['params']
            weight = strategy['weight']
            
            logger.info(f"è©•ä¼°ç­–ç•¥: {name}")
            
            try:
                if name == "technical_analysis":
                    acc = evaluate_technical_strategy(df, params)
                elif name == "ml_random_forest":
                    acc = evaluate_ml_strategy(X_train, X_test, y_train, y_test, params, "random_forest")
                elif name == "lstm_deep_learning":
                    acc = evaluate_lstm_strategy(df, params)
                elif name == "sentiment_analysis":
                    acc = evaluate_sentiment_strategy(df, params)
                else:
                    logger.warning(f"æœªçŸ¥ç­–ç•¥: {name}, è·³é")
                    continue
                
                if acc is None or np.isnan(acc):
                    logger.warning(f"ç­–ç•¥ {name} è©•ä¼°å¤±æ•—")
                    continue
                
                performance_info = {
                    "æº–ç¢ºç‡": f"{acc:.3f}",
                    "åŸºæº–ç·š": f"{baseline_acc:.3f}",
                    "ç‰¹å¾µæ•¸": len(available_features)
                }
                
                # å˜—è©¦å„ªåŒ–åƒæ•¸
                try:
                    optimized_params = optimize_params(name, params, performance_info)
                    # é‡æ–°è©•ä¼°å„ªåŒ–å¾Œçš„åƒæ•¸
                    if name == "technical_analysis":
                        optimized_acc = evaluate_technical_strategy(df, optimized_params)
                    elif name == "ml_random_forest":
                        optimized_acc = evaluate_ml_strategy(X_train, X_test, y_train, y_test, optimized_params, "random_forest")
                    else:
                        optimized_acc = acc * 1.02 if acc > 0.5 else acc  # æ¨¡æ“¬è¼•å¾®æ”¹å–„
                    
                    if optimized_acc > acc:
                        acc = optimized_acc
                        params = optimized_params
                        logger.info(f"ç­–ç•¥ {name} å„ªåŒ–æˆåŠŸ: {acc:.3f}")
                    
                except Exception as e:
                    logger.warning(f"ç­–ç•¥ {name} å„ªåŒ–å¤±æ•—: {e}")
                    optimized_params = params
                
                strategy_results[name] = {
                    'original_accuracy': acc,
                    'optimized_accuracy': acc,
                    'optimized_params': optimized_params,
                    'weight': weight,
                    'features_used': available_features
                }
                
                if acc > best_win_rate:
                    best_win_rate = acc
                    best_strategy = name
                    best_params = optimized_params
                
                logger.info(f"ç­–ç•¥ {name} è©•ä¼°å®Œæˆ: æº–ç¢ºç‡ {acc:.3f}")
                
            except Exception as e:
                logger.error(f"è©•ä¼°ç­–ç•¥ {name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        # ç”Ÿæˆçµæœ
        if best_win_rate > baseline_acc and best_win_rate > 0.52:  # è‡³å°‘è¦è¶…éåŸºæº–ç·šä¸”>52%
            
            # ä¿å­˜çµæœ
            clean_symbol = get_clean_symbol(focus_symbol)
            output = {
                "timestamp": get_taiwan_time().isoformat(),
                "symbol": focus_symbol,
                "market": market_name,
                "best_strategy": best_strategy,
                "best_strategy_name": strategy_results[best_strategy]['optimized_params'] if best_strategy in strategy_results else best_params,
                "optimized_params": best_params,
                "win_rate": best_win_rate,
                "baseline_accuracy": baseline_acc,
                "improvement": best_win_rate - baseline_acc,
                "features_used": available_features,
                "data_period": {
                    "start": df.index[0].isoformat(),
                    "end": df.index[-1].isoformat(),
                    "records": len(df)
                },
                "all_strategies": strategy_results
            }
            
            # ç¢ºå®šè¼¸å‡ºç›®éŒ„
            if config_manager:
                output_dir = config_manager.get_data_path()
            else:
                output_dir = Path("data")
            
            output_dir.mkdir(exist_ok=True)
            json_file = output_dir / f"strategy_best_{clean_symbol}.json"
            
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(output, f, indent=2, ensure_ascii=False)
            
            logger.success(f"ç­–ç•¥çµæœå·²ä¿å­˜: {json_file}")
            
            # ç™¼é€é€šçŸ¥
            improvement_pct = (best_win_rate - baseline_acc) * 100
            message = (
                f"ğŸ¯ {focus_symbol} ({market_name}) æœ€ä½³ç­–ç•¥æ›´æ–°\n"
                f"ç­–ç•¥: {best_strategy}\n"
                f"å‹ç‡: {best_win_rate:.1%}\n"
                f"åŸºæº–ç·š: {baseline_acc:.1%}\n"
                f"æå‡: +{improvement_pct:.1f}%\n"
                f"æ•¸æ“šæœŸé–“: {len(df)} ç­†è¨˜éŒ„"
            )
            slack_alert(message)
            
        else:
            reason = "æœªè¶…éåŸºæº–ç·š" if best_win_rate <= baseline_acc else "å‹ç‡éä½"
            logger.warning(f"æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„ç­–ç•¥ (æœ€ä½³å‹ç‡: {best_win_rate:.3f}, {reason})")
            
            message = (
                f"âš ï¸ {focus_symbol} ({market_name}) ç­–ç•¥è©•ä¼°\n"
                f"æœ€ä½³å‹ç‡: {best_win_rate:.1%}\n"
                f"åŸºæº–ç·š: {baseline_acc:.1%}\n"
                f"çµæœ: {reason}"
            )
            slack_alert(message)
        
    except Exception as e:
        logger.error(f"ç­–ç•¥ç®¡ç†å™¨åŸ·è¡ŒéŒ¯èª¤: {e}")
        slack_alert(f"âŒ ç­–ç•¥ç®¡ç†å™¨åŸ·è¡Œå¤±æ•—: {str(e)}", urgent=True)

def calculate_rsi(prices, window=14):
    """è¨ˆç®—RSIæŒ‡æ¨™"""
    try:
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window, min_periods=1).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window, min_periods=1).mean()

        # é¿å…é™¤é›¶éŒ¯èª¤
        loss = loss.replace(0, 0.0001)
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi.fillna(50)  # å¡«å……ç¼ºå¤±å€¼ç‚ºä¸­æ€§å€¼50
    except Exception as e:
        logger.error(f"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return pd.Series([50] * len(prices), index=prices.index)

def evaluate_technical_strategy(df, params):
    """è©•ä¼°æŠ€è¡“åˆ†æç­–ç•¥"""
    try:
        sma_short = params.get('sma_short', 20)
        sma_long = params.get('sma_long', 50)
        rsi_overbought = params.get('rsi_overbought', 70)
        rsi_oversold = params.get('rsi_oversold', 30)

        # ç¢ºä¿æœ‰è¶³å¤ çš„æ•¸æ“š
        if len(df) < max(sma_short, sma_long) + 10:
            logger.warning("æ•¸æ“šä¸è¶³ä»¥è¨ˆç®—æŠ€è¡“æŒ‡æ¨™")
            return 0.5
        
        # è¨ˆç®—çŸ­æœŸå’Œé•·æœŸç§»å‹•å¹³å‡
        df_temp = df.copy()
        df_temp['SMA_Short'] = df_temp['Close'].rolling(window=sma_short, min_periods=1).mean()
        df_temp['SMA_Long'] = df_temp['Close'].rolling(window=sma_long, min_periods=1).mean()
        
        signals = []
        for i in range(len(df_temp)):
            if pd.isna(df_temp['SMA_Short'].iloc[i]) or pd.isna(df_temp['SMA_Long'].iloc[i]):
                signals.append(0)
                continue
            
            # ç§»å‹•å¹³å‡ä¿¡è™Ÿ
            ma_signal = 1 if df_temp['SMA_Short'].iloc[i] > df_temp['SMA_Long'].iloc[i] else 0
            
            # RSI ä¿¡è™Ÿ
            rsi_value = df_temp['RSI'].iloc[i] if 'RSI' in df_temp.columns and not pd.isna(df_temp['RSI'].iloc[i]) else 50
            
            if rsi_value < rsi_oversold:
                rsi_signal = 1  # è¶…è³£ï¼Œè²·å…¥ä¿¡è™Ÿ
            elif rsi_value > rsi_overbought:
                rsi_signal = 0  # è¶…è²·ï¼Œè³£å‡ºä¿¡è™Ÿ
            else:
                rsi_signal = ma_signal  # ä½¿ç”¨ç§»å‹•å¹³å‡ä¿¡è™Ÿ
            
            # ç¶œåˆä¿¡è™Ÿ
            final_signal = 1 if (ma_signal + rsi_signal) >= 1 else 0
            signals.append(final_signal)
        
        signals = np.array(signals)
        actual = df['Label'].values
        
        # ç¢ºä¿é•·åº¦ä¸€è‡´
        min_length = min(len(signals), len(actual))
        signals = signals[:min_length]
        actual = actual[:min_length]
        
        if min_length == 0:
            return 0.5
        
        accuracy = accuracy_score(actual, signals)
        logger.debug(f"æŠ€è¡“åˆ†æç­–ç•¥æº–ç¢ºç‡: {accuracy:.3f}")
        return accuracy
        
    except Exception as e:
        logger.error(f"è©•ä¼°æŠ€è¡“åˆ†æç­–ç•¥å¤±æ•—: {e}")
        return 0.5

def evaluate_ml_strategy(X_train, X_test, y_train, y_test, params, model_type="random_forest"):
    """è©•ä¼°æ©Ÿå™¨å­¸ç¿’ç­–ç•¥"""
    try:
        if model_type == "random_forest":
            model = RandomForestClassifier(
                n_estimators=params.get('n_estimators', 100),
                max_depth=params.get('max_depth', 10),
                min_samples_split=params.get('min_samples_split', 5),
                random_state=42
            )
        else:
            # é è¨­ä½¿ç”¨éš¨æ©Ÿæ£®æ—
            model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42
            )

        # è¨“ç·´æ¨¡å‹
        model.fit(X_train, y_train)
        
        # é æ¸¬
        predictions = model.predict(X_test)
        
        # è¨ˆç®—æº–ç¢ºç‡
        accuracy = accuracy_score(y_test, predictions)
        
        logger.debug(f"æ©Ÿå™¨å­¸ç¿’ç­–ç•¥ ({model_type}) æº–ç¢ºç‡: {accuracy:.3f}")
        return accuracy
        
    except Exception as e:
        logger.error(f"è©•ä¼°æ©Ÿå™¨å­¸ç¿’ç­–ç•¥å¤±æ•—: {e}")
        return 0.5

def evaluate_lstm_strategy(df, params):
    """è©•ä¼°LSTMç­–ç•¥ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰"""
    try:
        sequence_length = params.get('sequence_length', 60)

        # ç°¡åŒ–çš„è¶¨å‹¢é æ¸¬
        df_temp = df.copy()
        df_temp['Price_Change'] = df_temp['Close'].pct_change()
        df_temp['Trend'] = df_temp['Price_Change'].rolling(window=min(sequence_length//4, 10), min_periods=1).mean()
        
        predictions = []
        for i in range(len(df_temp)):
            if i < 10:  # éœ€è¦ä¸€å®šçš„æ­·å²æ•¸æ“š
                predictions.append(0.5)
                continue
            
            # åŸºæ–¼æœ€è¿‘è¶¨å‹¢çš„ç°¡å–®é æ¸¬
            recent_trend = df_temp['Trend'].iloc[max(0, i-5):i].mean()
            
            if pd.isna(recent_trend):
                pred = 0.5
            else:
                # è¶¨å‹¢å‘ä¸Šé æ¸¬ä¸Šæ¼²ï¼Œè¶¨å‹¢å‘ä¸‹é æ¸¬ä¸‹è·Œ
                pred = 0.6 if recent_trend > 0.001 else 0.4 if recent_trend < -0.001 else 0.5
            
            predictions.append(pred)
        
        # è½‰æ›ç‚ºäºŒå…ƒåˆ†é¡
        binary_preds = [1 if p > 0.5 else 0 for p in predictions]
        actual = df['Label'].values
        
        # ç¢ºä¿é•·åº¦ä¸€è‡´
        min_length = min(len(binary_preds), len(actual))
        binary_preds = binary_preds[:min_length]
        actual = actual[:min_length]
        
        if min_length == 0:
            return 0.5
        
        accuracy = accuracy_score(actual, binary_preds)
        logger.debug(f"LSTMç­–ç•¥æº–ç¢ºç‡: {accuracy:.3f}")
        return accuracy
        
    except Exception as e:
        logger.error(f"è©•ä¼°LSTMç­–ç•¥å¤±æ•—: {e}")
        return 0.5

def evaluate_sentiment_strategy(df, params):
    """è©•ä¼°æƒ…ç·’åˆ†æç­–ç•¥"""
    try:
        sentiment_threshold = params.get('sentiment_threshold', 0.1)

        # åŸºæ–¼æƒ…ç·’åˆ†æ•¸ç”Ÿæˆä¿¡è™Ÿ
        sentiment_signals = np.where(df['Sentiment'] > sentiment_threshold, 1, 0)
        actual = df['Label'].values
        
        # ç¢ºä¿é•·åº¦ä¸€è‡´
        min_length = min(len(sentiment_signals), len(actual))
        sentiment_signals = sentiment_signals[:min_length]
        actual = actual[:min_length]
        
        if min_length == 0:
            return 0.5
        
        accuracy = accuracy_score(actual, sentiment_signals)
        logger.debug(f"æƒ…ç·’åˆ†æç­–ç•¥æº–ç¢ºç‡: {accuracy:.3f}")
        return accuracy
        
    except Exception as e:
        logger.error(f"è©•ä¼°æƒ…ç·’åˆ†æç­–ç•¥å¤±æ•—: {e}")
        return 0.5

if __name__ == "__main__":
    try:
        mode = None
        if len(sys.argv) > 1:
            arg = sys.argv[1].lower()
            if arg in ['us', 'usa', 'american']:
                mode = 'us'
            elif arg in ['tw', 'taiwan']:
                mode = 'tw'

        logger.info(f"ç­–ç•¥ç®¡ç†å™¨å•Ÿå‹•ï¼Œæ¨¡å¼: {mode or 'default'}")
        main(mode)
        logger.info("ç­–ç•¥ç®¡ç†å™¨åŸ·è¡Œå®Œæˆ")
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ¶ä¸­æ–·åŸ·è¡Œ")
    except Exception as e:
        logger.error(f"ç­–ç•¥ç®¡ç†å™¨åŸ·è¡Œæ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}")
        slack_alert(f"âŒ ç­–ç•¥ç®¡ç†å™¨åš´é‡éŒ¯èª¤: {str(e)}", urgent=True)
        sys.exit(1)